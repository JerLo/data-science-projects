{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#483D8B\">\n",
    "<h1 align=\"center\"> Semi-Supervised Learning</h1>\n",
    "<h3 align=\"center\"> Jeremy Lopez</h3>\n",
    "<h3 align=\"center\"> 11/28/18</h3>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# Overview\n",
    "\n",
    "This notebook will aim to predict the duration of testing a Mercedes-Benz car based on its features. Note that the car features have been kept anonymous in the dataset (X0, X1, X2, ...). This notebook will also demonstrate an implementation of a semi-supervised learning method known as pseudo-labeling because the dataset does contain a fair amount of unlabeled data. Before the implementation process begins, the provided dataset will be preprocessed and explored. Once the data is ready, a pseudo-learning regression model will be implemented and tested using labeled and unlabeled data. Then the implemented model will be compared with an XGBoost regression model that does not perform pseudo-labeling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# Background\n",
    "\n",
    "### Supervised Learning\n",
    "\n",
    "* Supervised learning is where you have both input variables AND an output variable\n",
    "\n",
    "\n",
    "* An algorithm can be used to learn the mapping function from the input to the output\n",
    "    * Y = f(X)\n",
    "    \n",
    "    \n",
    "* Process of an algorithm learning from the training dataset\n",
    "    * A teacher supervising the learning process\n",
    "    * Teacher has the correct answers\n",
    "    * Algorithm iteratively makes predictions on the training data and is corrected by the teacher\n",
    "    * Learning stops when the algorithm achieves an acceptable level of performance\n",
    "    \n",
    "    \n",
    "* Examples:\n",
    "    * Classification\n",
    "        * output variable is a category\n",
    "        * \"red\", \"blue\", \"disease\", \"no disease\"\n",
    "    * Regression \n",
    "        * output variable is a real value\n",
    "        * \"dollars\", \"weight\"\n",
    "        \n",
    "\n",
    "### Unsupervised Learning\n",
    "\n",
    "* Unlike supervised learning, unsupervised learning deals with input data that has no corresponding output variables\n",
    "\n",
    "\n",
    "* The main goal with unsupervised learning is to model the distribution of the data in order to learn more about it.\n",
    "\n",
    "\n",
    "* Algorithms are left to find and reveal the underlying structure of the data\n",
    "    * There is no supervising teacher\n",
    "    * With no teacher, there are no right answers\n",
    "    \n",
    "    \n",
    "* Examples:\n",
    "    * Clustering\n",
    "        * want to discover groupings in the data\n",
    "        * grouping customers by purchasing behavior\n",
    "    * Association\n",
    "        * discover rules that describe larger portions of your data\n",
    "        * \"people who buy X also tend to buy Y\"\n",
    "        \n",
    "        \n",
    "### Semi-Supervised Learning\n",
    "    \n",
    "\n",
    "* There is a large amount of available input data (X) but only some the output data is known (Y)\n",
    "\n",
    "\n",
    "* Semi-supervised learning deals with finding the rest of the unknown output data, which is usually just unlabeled data\n",
    "\n",
    "\n",
    "* Supervised and unsupervised learning techniques can be used to make predictions for the unlabeled data\n",
    "\n",
    "\n",
    "* This notebook will approach a semi-supervised learning problem with a dataset that mostly contains unlabeled data using a technique called pseudo-labeling\n",
    "\n",
    "\n",
    "### What is Pseudo-labeling?\n",
    "\n",
    "* First, train the model on the available labeled data\n",
    "\n",
    "\n",
    "* Then, use the trained model to predict labels for the unlabeled data, which creates \"pseudo-labels\"\n",
    "\n",
    "\n",
    "* Lastly, combine both the labeled and newly pseudo-labeled data in a new dataset that is used to train the data\n",
    "\n",
    "\n",
    "* The pseudo-labeling process can be summarized with the image shown below: \n",
    "\n",
    "<img src=\"https://datawhatnow.com/wp-content/uploads/2017/08/pseudo-labeling-683x1024.png\" alt=\"Testing\" style=\"width:300px;height:450px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset used in this notebook is from the Mercedes-Benz Greener Manufacturing Kaggle competition. The data ('train.csv' and 'test.csv') can be downloaded from the competition website (https://www.kaggle.com/c/mercedes-benz-greener-manufacturing/data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4209, 378) (4209, 377)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "print(train.shape, test.shape)\n",
    "# (4209, 378) (4209, 377)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>y</th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X8</th>\n",
       "      <th>...</th>\n",
       "      <th>X375</th>\n",
       "      <th>X376</th>\n",
       "      <th>X377</th>\n",
       "      <th>X378</th>\n",
       "      <th>X379</th>\n",
       "      <th>X380</th>\n",
       "      <th>X382</th>\n",
       "      <th>X383</th>\n",
       "      <th>X384</th>\n",
       "      <th>X385</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>130.81</td>\n",
       "      <td>k</td>\n",
       "      <td>v</td>\n",
       "      <td>at</td>\n",
       "      <td>a</td>\n",
       "      <td>d</td>\n",
       "      <td>u</td>\n",
       "      <td>j</td>\n",
       "      <td>o</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>88.53</td>\n",
       "      <td>k</td>\n",
       "      <td>t</td>\n",
       "      <td>av</td>\n",
       "      <td>e</td>\n",
       "      <td>d</td>\n",
       "      <td>y</td>\n",
       "      <td>l</td>\n",
       "      <td>o</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>76.26</td>\n",
       "      <td>az</td>\n",
       "      <td>w</td>\n",
       "      <td>n</td>\n",
       "      <td>c</td>\n",
       "      <td>d</td>\n",
       "      <td>x</td>\n",
       "      <td>j</td>\n",
       "      <td>x</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>80.62</td>\n",
       "      <td>az</td>\n",
       "      <td>t</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>x</td>\n",
       "      <td>l</td>\n",
       "      <td>e</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>78.02</td>\n",
       "      <td>az</td>\n",
       "      <td>v</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>h</td>\n",
       "      <td>d</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 378 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID       y  X0 X1  X2 X3 X4 X5 X6 X8  ...   X375  X376  X377  X378  X379  \\\n",
       "0   0  130.81   k  v  at  a  d  u  j  o  ...      0     0     1     0     0   \n",
       "1   6   88.53   k  t  av  e  d  y  l  o  ...      1     0     0     0     0   \n",
       "2   7   76.26  az  w   n  c  d  x  j  x  ...      0     0     0     0     0   \n",
       "3   9   80.62  az  t   n  f  d  x  l  e  ...      0     0     0     0     0   \n",
       "4  13   78.02  az  v   n  f  d  h  d  n  ...      0     0     0     0     0   \n",
       "\n",
       "   X380  X382  X383  X384  X385  \n",
       "0     0     0     0     0     0  \n",
       "1     0     0     0     0     0  \n",
       "2     0     1     0     0     0  \n",
       "3     0     0     0     0     0  \n",
       "4     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 378 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# Exploratory Data Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a quick glance of the data, we can see that the first couple of features are assigned non-numerical values. Features X0-X8 are categorical variables and we need to transform them into numerical values. This can be done using  scikit-learn’s LabelEncoder class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features = train.columns[2:]\n",
    "\n",
    "for column_name in features:\n",
    "    label_encoder = LabelEncoder() \n",
    "    \n",
    "    # Get the column values\n",
    "    train_column_values = list(train[column_name].values)\n",
    "    test_column_values = list(test[column_name].values)\n",
    "    \n",
    "    # Fit the label encoder\n",
    "    label_encoder.fit(train_column_values + test_column_values)\n",
    "    \n",
    "    # Transform the feature\n",
    "    train[column_name] = label_encoder.transform(train_column_values)\n",
    "    test[column_name] = label_encoder.transform(test_column_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>y</th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X8</th>\n",
       "      <th>...</th>\n",
       "      <th>X375</th>\n",
       "      <th>X376</th>\n",
       "      <th>X377</th>\n",
       "      <th>X378</th>\n",
       "      <th>X379</th>\n",
       "      <th>X380</th>\n",
       "      <th>X382</th>\n",
       "      <th>X383</th>\n",
       "      <th>X384</th>\n",
       "      <th>X385</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>130.81</td>\n",
       "      <td>37</td>\n",
       "      <td>23</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>88.53</td>\n",
       "      <td>37</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>76.26</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>80.62</td>\n",
       "      <td>24</td>\n",
       "      <td>21</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>78.02</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 378 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID       y  X0  X1  X2  X3  X4  X5  X6  X8  ...   X375  X376  X377  X378  \\\n",
       "0   0  130.81  37  23  20   0   3  27   9  14  ...      0     0     1     0   \n",
       "1   6   88.53  37  21  22   4   3  31  11  14  ...      1     0     0     0   \n",
       "2   7   76.26  24  24  38   2   3  30   9  23  ...      0     0     0     0   \n",
       "3   9   80.62  24  21  38   5   3  30  11   4  ...      0     0     0     0   \n",
       "4  13   78.02  24  23  38   5   3  14   3  13  ...      0     0     0     0   \n",
       "\n",
       "   X379  X380  X382  X383  X384  X385  \n",
       "0     0     0     0     0     0     0  \n",
       "1     0     0     0     0     0     0  \n",
       "2     0     0     1     0     0     0  \n",
       "3     0     0     0     0     0     0  \n",
       "4     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 378 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is now ready for the model implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "\n",
    "\n",
    "First, we will create a function that will create an \"augmented training set\". This created data set will consist of both pseudo-labeled and labeled data. The arguments of the function are the model, training and test set information (data and features), and a parameter called sample_rate. Sample_rate allows us to control the percent of pseudo-labeled data that we will mix with the initially labeled data. For example, setting sample_rate to 0 means that the model will only use the labeled data this is already available. Setting the sample_rate to 0.5 means that the model will use all the labeled data and only half of the pseudo-labeled data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_augmented_train(X, y, model, test, features, target, sample_rate):\n",
    "    '''\n",
    "    Create and return the augmented_train set that consists\n",
    "    of pseudo-labeled and labeled data.\n",
    "    '''\n",
    "    num_of_samples = int(len(test) * sample_rate)\n",
    "\n",
    "    # Train the model and create the pseudo-labels\n",
    "    model.fit(X, y)\n",
    "    pseudo_labels = model.predict(test[features])\n",
    "\n",
    "    # Add the pseudo-labels to the test set\n",
    "    augmented_test = test.copy(deep=True)\n",
    "    augmented_test[target] = pseudo_labels\n",
    "\n",
    "    # Take a subset of the test set with pseudo-labels and append in onto\n",
    "    # the training set\n",
    "    sampled_test = augmented_test.sample(n=num_of_samples)\n",
    "    temp_train = pd.concat([X, y], axis=1)\n",
    "    augemented_train = pd.concat([sampled_test, temp_train])\n",
    "    \n",
    "    # Shuffle the augmented dataset and return it\n",
    "    return shuffle(augemented_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will need a fit method that will train the model using the recently created augmented training set. It will take the same arguments as the `create_augmented_train()` function, minus the `test` and parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X, y, model, features, target, sample_rate):\n",
    "    \n",
    "    # train the model using the augmented_train set if sample_rate is > 0.0\n",
    "    if sample_rate > 0.0:\n",
    "        augemented_train = create_augmented_train(X, y)\n",
    "        model.fit(\n",
    "            augemented_train[features],\n",
    "            augemented_train[target]\n",
    "        )\n",
    "    else:\n",
    "        model.fit(X, y)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since both of our implemented functions take in a lot of arguments, it will be easier to create a class in order to unify and clean all of our code. A class will also give us the opportunity to add more functions if we need any. Below is our defined class, `PseudoLabeler`, which contains the previously defined functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "\n",
    "class PseudoLabeler(BaseEstimator, RegressorMixin):\n",
    "    \n",
    "    def __init__(self, model, test, features, target, sample_rate=0.2, seed=42):\n",
    "        self.sample_rate = sample_rate\n",
    "        self.seed = seed\n",
    "        self.model = model\n",
    "        self.model.seed = seed\n",
    "        \n",
    "        self.test = test\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "        \n",
    "    def get_params(self, deep=True):\n",
    "        return {\n",
    "            \"sample_rate\": self.sample_rate,\n",
    "            \"seed\": self.seed,\n",
    "            \"model\": self.model,\n",
    "            \"test\": self.test,\n",
    "            \"features\": self.features,\n",
    "            \"target\": self.target\n",
    "        }\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        if self.sample_rate > 0.0:\n",
    "            augemented_train = self.create_augmented_train(X, y)\n",
    "            self.model.fit(\n",
    "                augemented_train[self.features],\n",
    "                augemented_train[self.target]\n",
    "            )\n",
    "        else:\n",
    "            self.model.fit(X, y)\n",
    "        \n",
    "        return self\n",
    "\n",
    "\n",
    "    def create_augmented_train(self, X, y):\n",
    "        num_of_samples = int(len(test) * self.sample_rate)\n",
    "        \n",
    "        # Train the model and creat the pseudo-labels\n",
    "        self.model.fit(X, y)\n",
    "        pseudo_labels = self.model.predict(self.test[self.features])\n",
    "        \n",
    "        # Add the pseudo-labels to the test set\n",
    "        augmented_test = test.copy(deep=True)\n",
    "        augmented_test[self.target] = pseudo_labels\n",
    "        \n",
    "        # Take a subset of the test set with pseudo-labels and append in onto\n",
    "        # the training set\n",
    "        sampled_test = augmented_test.sample(n=num_of_samples)\n",
    "        temp_train = pd.concat([X, y], axis=1)\n",
    "        augemented_train = pd.concat([sampled_test, temp_train])\n",
    "\n",
    "        return shuffle(augemented_train)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    def get_model_name(self):\n",
    "        return self.model.__class__.__name__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the `PseudoLabeler` class has been fully implemented, we need a model to use as one of the parameters, `model`, for the initialization of the class. Below, we will compare some models that can be imported from the sklearn library using the coefficient of determination (R2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import BayesianRidge, Ridge, ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor     CV-5 R2:  0.43 (+/- 0.02)\n",
      "XGBRegressor              CV-5 R2:  0.55 (+/- 0.06)\n",
      "MLPRegressor              CV-5 R2:  0.49 (+/- 0.07)\n",
      "Ridge                     CV-5 R2:  0.52 (+/- 0.08)\n",
      "BayesianRidge             CV-5 R2:  0.54 (+/- 0.07)\n",
      "ExtraTreesRegressor       CV-5 R2:  0.37 (+/- 0.07)\n",
      "ElasticNet                CV-5 R2:  0.35 (+/- 0.06)\n",
      "KNeighborsRegressor       CV-5 R2:  0.27 (+/- 0.04)\n",
      "GradientBoostingRegressor CV-5 R2:  0.54 (+/- 0.07)\n"
     ]
    }
   ],
   "source": [
    "model_factory = [\n",
    "    RandomForestRegressor(),\n",
    "    XGBRegressor(nthread=1),\n",
    "    MLPRegressor(),\n",
    "    Ridge(),\n",
    "    BayesianRidge(),\n",
    "    ExtraTreesRegressor(),\n",
    "    ElasticNet(),\n",
    "    KNeighborsRegressor(),\n",
    "    GradientBoostingRegressor()\n",
    "]\n",
    "\n",
    "for model in model_factory:\n",
    "    model.seed = 42\n",
    "    num_folds = 3\n",
    "\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=num_folds, scoring='r2', n_jobs=8)\n",
    "    score_description = \" %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2)\n",
    "\n",
    "    print('{model:25} CV-5 R2: {score}'.format(\n",
    "        model=model.__class__.__name__,\n",
    "        score=score_description\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the results of each model, the XGBRegressor model scored the highest mean score with an average standard deviation. Therefore, the `PseudoLabeler` class will be implemented using the XGBRegressor model. This is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([117.541885,  92.00364 ,  76.15129 , ..., 110.52514 ,  92.19561 ,\n",
       "        94.57087 ], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'y'\n",
    "\n",
    "# Preprocess the data\n",
    "X_train, X_test = train[features], test[features]\n",
    "y_train = train[target]\n",
    "\n",
    "# Create the PseudoLabeler with XGBRegressor as the base regressor\n",
    "model = PseudoLabeler(\n",
    "    XGBRegressor(nthread=1),\n",
    "    test,\n",
    "    features,\n",
    "    target\n",
    ")\n",
    "\n",
    "# Train the model and use it to predict\n",
    "model.fit(X_train, y_train)\n",
    "model.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance (vs Default XGBoost Regression)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test out the `PseudoLabeler`, we will compare it to the default XGBRegressor model using the R2-score as the evaluation metric again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor              CV-8 R2: 0.5671 (+/- 0.1596)\n",
      "PseudoLabeler             CV-8 R2: 0.5693 (+/- 0.1604)\n"
     ]
    }
   ],
   "source": [
    "model_factory = [\n",
    "    XGBRegressor(nthread=1),\n",
    "    \n",
    "    PseudoLabeler(\n",
    "        XGBRegressor(nthread=1),\n",
    "        test,\n",
    "        features,\n",
    "        target,\n",
    "        sample_rate=0.3\n",
    "    ),\n",
    "]\n",
    "\n",
    "for model in model_factory:\n",
    "    model.seed = 42\n",
    "    num_folds = 8\n",
    "    \n",
    "    scores = cross_val_score(model, X_train, y_train, cv=num_folds, scoring='r2', n_jobs=8)\n",
    "    score_description = \"R2: %0.4f (+/- %0.4f)\" % (scores.mean(), scores.std() * 2)\n",
    "\n",
    "    print('{model:25} CV-{num_folds} {score_cv}'.format(\n",
    "        model=model.__class__.__name__,\n",
    "        num_folds=num_folds,\n",
    "        score_cv=score_description\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the the PseudoLabeler has a slightly higher mean score and lower standard deviation. This implies that the PseudoLabeler is a slightly superior model to the default XGBRegressor model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# Conclusion\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pseudo-labeling allows us to utilize unlabeled data while training machine learning models. It can also improve the performance of other models if the process is tuned and made to work properly. In this case, however, the XGBRegressor model was only slightly improved when it was implemented using pseudo-labeling. Note that this data set was obtained from a Kaggle competition so this very slight improvement in the R2-scores does make a difference. However, in the context of the actual business problem, this isn't very impressive and all of the time spent implementing the PseudoLabeler class could have instead been used to improve the default XGBRegression model and reducing the number of features in the dataset. However, we do end up with a model with a decent R2 score that will predict the amount of testing time for a vehicle given a combination of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "\n",
    "[1.] https://datawhatnow.com/pseudo-labeling-semi-supervised-learning/\n",
    "    \n",
    "[2.] https://github.com/Weenkus/DataWhatNow-Codes/blob/master/pseudo_labeling_a_simple_semi_supervised_learning_method/pseudo_labeling_a_simple_semi_supervised_learning_method.ipynb\n",
    "    \n",
    "[3.] https://www.analyticsvidhya.com/blog/2017/09/pseudo-labelling-semi-supervised-learning-technique/\n",
    "    \n",
    "[4.] https://scikit-learn.org/stable/modules/label_propagation.html\n",
    "    \n",
    "[5.] https://www.kaggle.com/residentmario/notes-on-semi-supervised-learning\n",
    "\n",
    "[6.] https://machinelearningmastery.com/supervised-and-unsupervised-machine-learning-algorithms/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
